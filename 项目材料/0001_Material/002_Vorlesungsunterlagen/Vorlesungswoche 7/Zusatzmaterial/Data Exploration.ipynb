{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Applications - Data Understanding\n",
    "\n",
    "<p> Practical examples for machine learning applications lecture No. 7 - Data Understanding </p>\n",
    "\n",
    "<h4> Contents </h4>\n",
    "\n",
    " 1. Data Understanding\n",
    " 2. Data Preprocessing <font color=\"red\">- see Jupyter notebook \"Data Preprocessing\"</font>\n",
    " 3. Feature Engineering <font color=\"red\">- see Jupyter notebook \"Data Preprocessing\"</font>\n",
    "\n",
    "First, we need to import the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Unterstanding\n",
    "\n",
    "<p> In a first step we will load the data and get an overview of the recorded parameters. We call this process Data Understanding. The idea is to analyse and describe the dataset with classical statistical methods in order to get an broad overview and idea of the parameters and their relevance. \n",
    "\n",
    "<p> We now start with importing the two dataset. The first on will contain samples of the light weight container, the second one will contain samples of the heavy weight container. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEV1</th>\n",
       "      <th>t</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV_1</td>\n",
       "      <td>331765</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV_1</td>\n",
       "      <td>331775</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV_1</td>\n",
       "      <td>331785</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DEV1       t  var_1  var_2  var_3\n",
       "0  DEV_1  331765  0.056  0.018  0.926\n",
       "1  DEV_1  331775 -0.004 -0.006  0.997\n",
       "2  DEV_1  331785  0.017  0.046  0.976"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PFAD ANPASSEN\"\"\"\n",
    "# Import files\n",
    "df_light_full = pd.read_csv(\"Matlab_Data_Training_output_leicht.csv\", header=None)\n",
    "df_heavy_full = pd.read_csv(\"Matlab_Data_Training_output_schwer.csv\", header=None)\n",
    "\n",
    "# Rename columns names\n",
    "df_light_full.columns = ['DEV1', 't', 'var_1', 'var_2', 'var_3']\n",
    "df_heavy_full.columns = ['DEV1', 't', 'var_1', 'var_2', 'var_3']\n",
    "\n",
    "# Drop NaNs\n",
    "df_heavy_full = df_heavy_full.dropna()\n",
    "df_light_full = df_light_full.dropna()\n",
    "\n",
    "# Show first values of dataset (good for checking correct formatting)\n",
    "df_heavy_full.head(3) \n",
    "df_light_full.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Basic descriptive statistics </h4>\n",
    "\n",
    "We will start the analysis by a simple statisitical descpription of the data. Pandas includes functions to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_heavy_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_light_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Visual inspection </h4>\n",
    "\n",
    "Plotting the three variables over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "df_heavy = df_heavy_full[[\"var_1\", \"var_2\", \"var_3\"]]\n",
    "\n",
    "plt.title(\"Heavy weight\")\n",
    "# plt.ylim(-1, 1.5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accelerations in m/s**2')\n",
    "ax1 = sns.lineplot(data=df_heavy)\n",
    "ax1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "df_light = df_light_full[[\"var_1\", \"var_2\", \"var_3\"]]\n",
    "\n",
    "plt.title(\"Light weight\")\n",
    "# plt.ylim(-1, 1.5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accelerations in m/s**2')\n",
    "ax2 = sns.lineplot(data=df_light)\n",
    "ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Delete all Zero Rows\"\"\"\n",
    "\n",
    "df_light = df_light.loc[(df_light!=0).any(axis=1)]\n",
    "df_heavy = df_heavy.loc[(df_heavy!=0).any(axis=1)]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Heavy weight\")\n",
    "plt.ylim(-1, 1.5)\n",
    "ax1 = sns.lineplot(data=df_heavy)\n",
    "ax1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a first impression of the data, we want to continue with statistical visualisation of the data. Very helpful is the visualization of the data distributions, for example in a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a historgram and kernel density estimate\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Distplot works fine with pandas slices\n",
    "sns.distplot(df_light[[\"var_1\"]], norm_hist=True, color=\"b\", label=\"Var 1\")\n",
    "sns.distplot(df_light[[\"var_2\"]], norm_hist=True, color=\"r\", label=\"Var 2\")\n",
    "sns.distplot(df_light[[\"var_3\"]], norm_hist=True, color=\"g\", label=\"Var 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Light weight\")\n",
    "plt.xlabel(\"Acceleration\")\n",
    "plt.ylabel(\"PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a historgram and kernel density estimate\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Distplot works fine with pandas slices\n",
    "sns.distplot(df_heavy[[\"var_1\"]], norm_hist=True, color=\"b\", label=\"Var 1\")\n",
    "sns.distplot(df_heavy[[\"var_2\"]], norm_hist=True, color=\"r\", label=\"Var 2\")\n",
    "sns.distplot(df_heavy[[\"var_3\"]], norm_hist=True, color=\"g\", label=\"Var 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Heavy weight\")\n",
    "# plt.ylim(0, 24)\n",
    "# plt.xlim(-0.5, 2)\n",
    "plt.xlabel(\"Acceleration\")\n",
    "plt.ylabel(\"PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_light.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analysis</h3>\n",
    "\n",
    "Now we will compare the two classes against each other rather than comparing the three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "var_names = ['var_1', 'var_2', 'var_3']\n",
    "\n",
    "for i, var in enumerate(var_names):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    sns.distplot(df_light[var], norm_hist=True, label=['light'])\n",
    "    sns.distplot(df_heavy[var], norm_hist=True, label=['heavy'])\n",
    "    plt.xlabel('')\n",
    "    plt.title(var)\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Basic explorative statistics </h4>\n",
    "\n",
    "Also very basic statistics show correlations between variables. Pandas again includes a function which computes by default the Pearson correlation coefficients. Spearman or Kendall are available as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_heavy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_light.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations can be plotted in form of 2D heatmaps. Of course, this gets more interesting if we have higher dimensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.matshow(df_light.corr(), cmap='viridis')\n",
    "plt.colorbar(cmap='viridis')\n",
    "plt.yticks(range(len(var_names)), var_names)\n",
    "plt.xticks(range(len(var_names)), var_names)\n",
    "# plt.title('Correlation matrix')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.scatter(df_light.var_1, df_light.var_2, alpha=0.6)\n",
    "plt.xlabel('Var1 = x')\n",
    "plt.ylabel('Var2 = y')\n",
    "plt.subplot(122)\n",
    "plt.scatter(df_light.var_1, df_light.var_3, alpha=0.6, c='C1')\n",
    "plt.xlabel('Var1 = x')\n",
    "plt.ylabel('Var3 = z')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
